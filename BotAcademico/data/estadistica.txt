ESTADÍSTICA Y PROBABILIDAD

1. CONCEPTOS BÁSICOS
La estadística es la ciencia que se ocupa de la recolección, análisis e interpretación de datos.

Tipos de datos:
- Cualitativos: categorías (color, género)
- Cuantitativos: números (altura, peso)
  - Discretos: conteos (número de hijos)
  - Continuos: mediciones (temperatura)

Población vs Muestra:
- Población: conjunto completo de elementos
- Muestra: subconjunto de la población
- Inferencia: usar la muestra para conocer la población

2. MEDIDAS DE TENDENCIA CENTRAL
Media aritmética: x̄ = (x₁ + x₂ + ... + xₙ)/n
- Sensible a valores extremos
- Más común en datos simétricos

Mediana: valor central cuando los datos están ordenados
- Robusta ante valores extremos
- Útil para datos asimétricos

Moda: valor que aparece con mayor frecuencia
- Puede no existir o ser múltiple
- Útil para datos categóricos

3. MEDIDAS DE DISPERSIÓN
Rango: diferencia entre el máximo y mínimo
R = xₘₐₓ - xₘᵢₙ

Varianza: promedio de los cuadrados de las desviaciones
s² = Σ(xᵢ - x̄)²/(n-1)

Desviación estándar: raíz cuadrada de la varianza
s = √s²

Coeficiente de variación: CV = s/x̄ × 100%
- Permite comparar dispersiones de diferentes datasets

4. PROBABILIDAD
Probabilidad: medida de la posibilidad de que ocurra un evento
P(A) = número de casos favorables / número de casos posibles

Propiedades:
- 0 ≤ P(A) ≤ 1
- P(A) + P(A^c) = 1 (evento complementario)
- P(∅) = 0, P(Ω) = 1

Reglas de probabilidad:
- Regla de la suma: P(A ∪ B) = P(A) + P(B) - P(A ∩ B)
- Regla del producto: P(A ∩ B) = P(A) × P(B|A)
- Eventos independientes: P(A ∩ B) = P(A) × P(B)

5. DISTRIBUCIONES DE PROBABILIDAD
Distribución Binomial: n ensayos independientes, probabilidad p de éxito
P(X = k) = C(n,k) × p^k × (1-p)^(n-k)
- Media: μ = np
- Varianza: σ² = np(1-p)

Distribución Normal: distribución continua en forma de campana
- Parámetros: μ (media) y σ (desviación estándar)
- Regla empírica: 68%-95%-99.7%
- Estandarización: Z = (X - μ)/σ

Distribución de Poisson: eventos raros en tiempo/espacio fijo
P(X = k) = (λ^k × e^(-λ))/k!
- λ es la tasa promedio de ocurrencia

6. TEOREMA DEL LÍMITE CENTRAL
Cuando n es grande, la distribución de medias muestrales se aproxima a una distribución normal, independientemente de la distribución original.

Consecuencias:
- Permite hacer inferencias sobre poblaciones no normales
- Base para muchos métodos estadísticos
- La aproximación mejora con n mayor

7. INTERVALOS DE CONFIANZA
Un intervalo de confianza estima un parámetro poblacional con cierto nivel de confianza.

Para la media (σ conocida):
IC = x̄ ± z_{α/2} × (σ/√n)

Para la media (σ desconocida):
IC = x̄ ± t_{α/2} × (s/√n)

Interpretación:
- 95% de confianza: si repitiera el muestreo muchas veces, 95% de los intervalos contendrían el parámetro real

8. PRUEBAS DE HIPÓTESIS
Proceso para tomar decisiones sobre parámetros poblacionales.

Pasos:
1. Formular hipótesis (H₀ y H₁)
2. Elegir nivel de significancia (α)
3. Calcular estadístico de prueba
4. Determinar valor p
5. Tomar decisión

Tipos de errores:
- Error Tipo I: rechazar H₀ cuando es verdadera (α)
- Error Tipo II: no rechazar H₀ cuando es falsa (β)

Pruebas comunes:
- Prueba t para medias
- Prueba z para proporciones
- Prueba χ² para independencia
- ANOVA para comparar múltiples medias

9. REGRESIÓN LINEAL
Modelo que relaciona una variable dependiente con una o más independientes.

Regresión lineal simple: y = β₀ + β₁x + ε

Método de mínimos cuadrados:
- Minimiza la suma de cuadrados de residuos
- β₁ = Σ(xᵢ - x̄)(yᵢ - ȳ) / Σ(xᵢ - x̄)²
- β₀ = ȳ - β₁x̄

Coeficiente de correlación: r = Σ(xᵢ - x̄)(yᵢ - ȳ) / √[Σ(xᵢ - x̄)² × Σ(yᵢ - ȳ)²]
- -1 ≤ r ≤ 1
- r² = proporción de varianza explicada